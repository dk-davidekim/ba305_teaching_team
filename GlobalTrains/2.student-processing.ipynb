{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"lime\">BA 305 - Team Exercise - Data Exploration + Cleaning<font> \n",
    "\n",
    "## Team Name:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.pexels.com/photos/253647/pexels-photo-253647.jpeg?cs=srgb&dl=pexels-j%C3%A9shoots-253647.jpg&fm=jpg&_gl=1*tdf1fi*_ga*MTg4MzYyOTk2Ny4xNzA5NDg1NDg2*_ga_8JE65Q40S6*MTcwOTQ4NTQ4NS4xLjEuMTcwOTQ4NTYyNC4wLjAuMA..\" width=\"800\" height=\"500\" alt=\"Train\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the early 1800s, when the first steam locomotive was built, Global Trains has led in rail innovation. This includes safety features, automatic brakes, and advanced navigation. Every year, Global Trains patents around 2000 new ideas, making it a leader in luxury train technology. It's part of the Global Transportation Group, known for high-end trains with many customization options for customers.\n",
    "\n",
    "To make sure each train is safe and works well before it's used, the company has a detailed testing process. However, testing all the different train setups quickly and efficiently is hard without smart algorithms. Global Trains is a top name in luxury trains, focusing on safety and efficient making of trains.\n",
    "\n",
    "Global Transportation Group is challenging people to help make train testing faster by solving a complex problem with a dataset of train features. The goal is to predict how long testing will take for each setup. The best solutions will make testing quicker, reduce environmental impact, and keep up the company's high quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "This dataset contains an anonymized set of variables, each representing a custom feature in a Global Trains locomotive. For instance, a variable might represent advanced braking systems, luxury seating options, or state-of-the-art navigation systems.\n",
    "\n",
    "The ground truth is labeled 'y' and indicates the time (in seconds) it took for each locomotive to pass testing for each specific feature.\n",
    "\n",
    "**File Descriptions:**\n",
    "- Variables labeled with letters are categorical.\n",
    "- Variables indicated by 0/1 represent binary values.\n",
    "\n",
    "**Files Included:**\n",
    "- `team_exercise_data.csv` - the dataset for train and test.\n",
    "- `test.csv` - the actual test dataset provided for evaluation purposes by the teaching team. Your task is to predict the 'y' variable for the 'ID's listed in this file.\n",
    "- `sample_submission.csv` - a sample submission file in the correct format.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Submissions are evaluated on the R^2 value, also called the coefficient of determination.\n",
    "\n",
    "https://www.investopedia.com/terms/r/r-squared.asp\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"lime\">Notebook Objective<font>\n",
    "\n",
    "The goal of this notebook is to conduct data exploration and data preparation alongside your team, setting the stage for the development and training of machine learning models throughout the remainder of the semester.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# TODO Add more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# TODO Change the path based on your set up\n",
    "\n",
    "df= pd.read_csv(\"team_exercise_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration + Cleaning\n",
    "\n",
    "Conduct data exploration and cleaning below. Feel free to use AI tools, online resources, and any other available technologies to accomplish the assigned tasks.\n",
    "\n",
    "<font color=\"red\"> Make sure you split the data into training and testing sets before applying any scaling operations!<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Change the 'processed_df' based on your set up\n",
    "\n",
    "processed_df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the processed data was correctly saved.\n",
    "\n",
    "check_df = pd.read_csv(\"processed_data.csv\")\n",
    "check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the Data Processing to test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test.csv` - the actual test dataset provided for evaluation purposes by the teaching team. Your task is to predict the 'y' variable for the 'ID's listed in this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Why?`\n",
    "\n",
    "Ensuring the test data is processed in the same way as the training data is crucial for maintaining the accuracy and effectiveness of a machine learning model. This consistency in preprocessing steps, such as scaling, handling missing values, and encoding categorical variables, ensures that the model receives test data in the format it expects, based on its training. Without matching preprocessing, the model might misinterpret the test data, leading to inaccurate predictions. Essentially, for the model to apply what it has learned accurately to new, unseen data, the feature space of the test data must closely align with that of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> If you've applied scaling earlier, remember to use the `transform` method instead of `fit_transform` for this test.csv data, as the scaler should be calibrated based on the original training data only.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Change the path based on your set up\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Repeat Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Processed test.csv Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Change the 'processed_submission_test' based on your set up\n",
    "\n",
    "processed_submission_test.to_csv('processed_submission_test.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the processed data was correctly saved.\n",
    "\n",
    "check_df_test = pd.read_csv(\"processed_submission_test.csv\", index_col=0)\n",
    "check_df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
